{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python==4.8.1.78 in c:\\users\\krish\\anaconda3\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from opencv-python==4.8.1.78) (1.25.2)\n",
      "Requirement already satisfied: numpy==1.25.2 in c:\\users\\krish\\anaconda3\\lib\\site-packages (1.25.2)\n",
      "Requirement already satisfied: tensorflow==2.15.0 in c:\\users\\krish\\appdata\\roaming\\python\\python311\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow==2.15.0) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (1.25.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (4.25.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (4.10.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (3.2.2)\n",
      "Requirement already satisfied: tqdm==4.66.2 in c:\\users\\krish\\anaconda3\\lib\\site-packages (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tqdm==4.66.2) (0.4.6)\n",
      "Requirement already satisfied: joblib==1.4.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (1.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user opencv-python==4.8.1.78\n",
    "!pip install --user numpy==1.25.2\n",
    "!pip install --user tensorflow==2.15.0\n",
    "!pip install --user tqdm==4.66.2\n",
    "!pip install --user joblib==1.4.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\krish\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "OpenCV version: 4.8.1\n",
      "NumPy version: 1.25.2\n",
      "TensorFlow version: 2.15.0\n",
      "tqdm version: 4.66.2\n",
      "Joblib version: 1.4.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "import joblib\n",
    "\n",
    "print(\"OpenCV version:\", cv2.__version__)\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"tqdm version:\", tqdm.__version__)\n",
    "print(\"Joblib version:\", joblib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data time: 0.0 seconds\n",
      "WARNING:tensorflow:From C:\\Users\\krish\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Loading data generator...\n",
      "Number of images found: 200\n",
      "6/6 [==============================] - ETA: 0s - total_loss: 3.6267 - illumination_smoothness_loss: 0.2214 - spatial_constancy_loss: 0.1309 - color_constancy_loss: 0.0670 - exposure_loss: 3.2074  Loading data generator...\n",
      "Number of images found: 200\n",
      "6/6 [==============================] - 461s 82s/step - total_loss: 3.5961 - illumination_smoothness_loss: 0.2027 - spatial_constancy_loss: 0.1190 - color_constancy_loss: 0.0592 - exposure_loss: 3.2152 - val_total_loss: 3.3841 - val_illumination_smoothness_loss: 0.0905 - val_spatial_constancy_loss: 0.0460 - val_color_constancy_loss: 0.0102 - val_exposure_loss: 3.2374\n",
      "Execution time: 468.3081376552582 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "MAX_TRAIN_IMAGES = 185\n",
    "\n",
    "def load_data(image_path, image_size):\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (image_size, image_size))\n",
    "        image = image / 255.0\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image from {image_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def get_image_paths(folder_path):\n",
    "    image_paths = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.png', '.jpg')):\n",
    "            image_paths.append(os.path.join(folder_path, filename))\n",
    "    return image_paths\n",
    "\n",
    "def data_generator(folder_path, batch_size=32, image_size=256):\n",
    "    print('Loading data generator...')\n",
    "    image_paths = get_image_paths(folder_path)\n",
    "    print('Number of images found: 200' )\n",
    "    num_samples = len(image_paths)\n",
    "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, len(image_paths))\n",
    "        batch_paths = image_paths[start_idx:end_idx]\n",
    "        batch_images = []\n",
    "        for image_path in batch_paths:\n",
    "            image_data = load_data(image_path, image_size)\n",
    "            if image_data is not None:\n",
    "                batch_images.append(image_data)\n",
    "        if batch_images:\n",
    "            yield  np.array(batch_images)\n",
    "\n",
    "def build_dce_net():\n",
    "    input_img = layers.Input(shape=[None, None, 3])\n",
    "    conv1 = layers.Conv2D(\n",
    "        32, (3, 3), strides=(1, 1), activation='relu', padding='same'\n",
    "    )(input_img)\n",
    "    conv2 = layers.Conv2D(\n",
    "        32, (3, 3), strides=(1, 1), activation='relu', padding='same'\n",
    "    )(conv1)\n",
    "    conv3 = layers.Conv2D(\n",
    "        32, (3, 3), strides=(1, 1), activation='relu', padding='same'\n",
    "    )(conv2)\n",
    "    conv4 = layers.Conv2D(\n",
    "        32, (3, 3), strides=(1, 1), activation='relu', padding='same'\n",
    "    )(conv3)\n",
    "    int_con1 = layers.Concatenate(axis=-1)([conv4, conv3])\n",
    "    conv5 = layers.Conv2D(\n",
    "        32, (3, 3), strides=(1, 1), activation='relu', padding='same'\n",
    "    )(int_con1)\n",
    "    int_con2 = layers.Concatenate(axis=-1)([conv5, conv2])\n",
    "    conv6 = layers.Conv2D(\n",
    "        32, (3, 3), strides=(1, 1), activation='relu', padding='same'\n",
    "    )(int_con2)\n",
    "    int_con3 = layers.Concatenate(axis=-1)([conv6, conv1])\n",
    "    x_r = layers.Conv2D(24, (3, 3), strides=(1, 1), activation='tanh', padding='same')(\n",
    "        int_con3\n",
    "    )\n",
    "    return Model(inputs=input_img, outputs=x_r)\n",
    "\n",
    "# Define custom loss functions\n",
    "def color_constancy_loss(x):\n",
    "    mean_rgb = tf.reduce_mean(x,axis=(1,2),keepdims=True)\n",
    "    mr,mg,mb = mean_rgb[:,:,:,0],mean_rgb[:,:,:,1],mean_rgb[:,:,:,2]\n",
    "    d_rg = tf.square(mr - mg)\n",
    "    d_rb = tf.square(mr - mb)\n",
    "    d_gb = tf.square(mb - mg)\n",
    "    return tf.sqrt(tf.square(d_rg) + tf.square(d_rb) + tf.square(d_gb))\n",
    "\n",
    "def exposure_loss(x, mean_val=0.6):\n",
    "    x = tf.reduce_mean(x, axis=3, keepdims=True)\n",
    "    mean = tf.nn.avg_pool2d(x, ksize=16, strides=16, padding='VALID')\n",
    "    return tf.reduce_mean(tf.square(mean - mean_val))\n",
    "\n",
    "def illumination_smoothness_loss(x):\n",
    "    batch_size = tf.shape(x)[0]\n",
    "    h_x = tf.shape(x)[1]\n",
    "    w_x = tf.shape(x)[2]\n",
    "    count_h = (tf.shape(x)[2] - 1) * tf.shape(x)[3]\n",
    "    count_w = tf.shape(x)[2] * (tf.shape(x)[3] - 1)\n",
    "    h_tv = tf.reduce_sum(tf.square((x[:,1:,:,:] - x[:,:h_x - 1, :, :])))\n",
    "    w_tv = tf.reduce_sum(tf.square((x[:,:,1:,:] - x[:,:,:w_x - 1, :])))\n",
    "    batch_size = tf.cast(count_h,dtype=tf.float32)\n",
    "    count_h = tf.cast(count_h,dtype=tf.float32)\n",
    "    count_w = tf.cast(count_w,dtype=tf.float32)\n",
    "    return 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n",
    "\n",
    "class SpatialConsistencyLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SpatialConsistencyLoss, self).__init__(**kwargs)\n",
    "        self.left_kernel = tf.constant([[[[0, 0, 0]], [[-1, 1, 0]], [[0, 0, 0]]]], dtype=tf.float32)\n",
    "        self.right_kernel = tf.constant([[[[0, 0, 0]], [[0, 1, -1]], [[0, 0, 0]]]], dtype=tf.float32)\n",
    "        self.up_kernel = tf.constant([[[[0, -1, 0]], [[0, 1, 0]], [[0, 0, 0]]]], dtype=tf.float32)\n",
    "        self.down_kernel = tf.constant([[[[0, 0, 0]], [[0, 1, 0]], [[0, -1, 0]]]], dtype=tf.float32)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        original_mean = tf.reduce_mean(y_true, 3, keepdims=True)\n",
    "        enhanced_mean = tf.reduce_mean(y_pred, 3, keepdims=True)\n",
    "        original_pool = tf.nn.avg_pool2d(original_mean, ksize=4, strides=4, padding=\"VALID\")\n",
    "        enhanced_pool = tf.nn.avg_pool2d(enhanced_mean, ksize=4, strides=4, padding=\"VALID\")\n",
    "        d_original_left = tf.nn.conv2d(original_pool, self.left_kernel, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        d_original_right = tf.nn.conv2d(original_pool, self.right_kernel, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        d_original_up = tf.nn.conv2d(original_pool, self.up_kernel, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        d_original_down = tf.nn.conv2d(original_pool, self.down_kernel, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        d_enhanced_left = tf.nn.conv2d(enhanced_pool, self.left_kernel, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        d_enhanced_right = tf.nn.conv2d(enhanced_pool, self.right_kernel, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        d_enhanced_up = tf.nn.conv2d(enhanced_pool, self.up_kernel, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        d_enhanced_down = tf.nn.conv2d(enhanced_pool, self.down_kernel, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "        d_left = tf.square(d_original_left - d_enhanced_left)\n",
    "        d_right = tf.square(d_original_right - d_enhanced_right)\n",
    "        d_up = tf.square(d_original_up - d_enhanced_up)\n",
    "        d_down = tf.square(d_original_down - d_enhanced_down)\n",
    "        return d_left + d_right + d_up + d_down\n",
    "\n",
    "class ZeroDCE(Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ZeroDCE, self).__init__(**kwargs)\n",
    "        self.dce_model = build_dce_net()\n",
    "        self.spatial_constancy_loss = SpatialConsistencyLoss()\n",
    "\n",
    "    def call(self, data):\n",
    "        return self.dce_model(data)\n",
    "\n",
    "    def compute_losses(self, data, output):\n",
    "        loss_spatial_constancy = tf.reduce_mean(self.spatial_constancy_loss(data, output))\n",
    "        loss_color_constancy = 5 * tf.reduce_mean(color_constancy_loss(output))\n",
    "        loss_exposure = 10 * tf.reduce_mean(exposure_loss(output))\n",
    "        loss_illumination = 200 * illumination_smoothness_loss(output)\n",
    "        total_loss = loss_spatial_constancy + loss_color_constancy + loss_exposure + loss_illumination\n",
    "        return {\n",
    "            \"total_loss\": total_loss,\n",
    "            \"illumination_smoothness_loss\": loss_illumination,\n",
    "            \"spatial_constancy_loss\": loss_spatial_constancy,\n",
    "            \"color_constancy_loss\": loss_color_constancy,\n",
    "            \"exposure_loss\": loss_exposure,\n",
    "        }\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = self.dce_model(data)\n",
    "            losses = self.compute_losses(data, output)\n",
    "        gradients = tape.gradient(losses[\"total_loss\"], self.dce_model.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.dce_model.trainable_weights))\n",
    "        return losses\n",
    "\n",
    "    def test_step(self, data):\n",
    "        output = self.dce_model(data)\n",
    "        return self.compute_losses(data, output)\n",
    "\n",
    "train_image_folder = 'first_zero_de_images'\n",
    "val_image_folder = 'first_zero_de_images'\n",
    "\n",
    "start_time = time.time()\n",
    "train_data_generator = data_generator(train_image_folder)\n",
    "val_data_generator = data_generator(val_image_folder)\n",
    "\n",
    "end_time = time.time()\n",
    "res1 = end_time-start_time\n",
    "print(\"data time: \" + str(res1) + \" seconds\")\n",
    "train_steps_per_epoch = len(get_image_paths(train_image_folder)) // BATCH_SIZE\n",
    "val_steps_per_epoch = len(get_image_paths(val_image_folder)) // BATCH_SIZE\n",
    "\n",
    "zero_dce_model = ZeroDCE()\n",
    "zero_dce_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
    "start2_time = time.time()\n",
    "history = zero_dce_model.fit(train_data_generator, steps_per_epoch=train_steps_per_epoch,\n",
    "                             validation_data=val_data_generator, validation_steps=val_steps_per_epoch,\n",
    "                             epochs=1)\n",
    "end2_time = time.time()\n",
    "res2 = end2_time - start2_time\n",
    "print(\"Execution time: \" + str(res2) + \" seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
