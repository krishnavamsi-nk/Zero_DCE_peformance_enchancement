{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzKI-rjkdLJm",
        "outputId": "10daff00-f758-414f-ee97-38816266a5e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the number of processes: 8\n",
            "Enter the number of threads per process: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data generator...Loading data generator...Loading data generator...\n",
            "Number of images found:\n",
            " \n",
            "Number of images found: Loading data generator...25\n",
            "Loading data generator..."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25Loading data generator...Loading data generator...Loading data generator...Number of images found:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Number of images found: Number of images found:"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of images found:Number of images found:Number of images found:2525\n",
            "    25252525\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:16<00:00, 16.66s/it]\n",
            "100%|██████████| 1/1 [00:23<00:00, 23.63s/it]\n",
            "100%|██████████| 1/1 [00:24<00:00, 24.86s/it]\n",
            "100%|██████████| 1/1 [00:25<00:00, 25.13s/it]\n",
            "100%|██████████| 1/1 [00:25<00:00, 25.37s/it]\n",
            "100%|██████████| 1/1 [00:25<00:00, 25.92s/it]\n",
            "100%|██████████| 1/1 [00:26<00:00, 26.43s/it]\n",
            "100%|██████████| 1/1 [00:26<00:00, 26.47s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data generator...Loading data generator...Loading data generator...Loading data generator...\n",
            "\n",
            "Number of images found:Loading data generator...Loading data generator...Loading data generator...Number of images found:\n",
            "  Loading data generator...\n",
            "\n",
            "\n",
            "\n",
            "Number of images found:Number of images found:Number of images found:Number of images found:  Number of images found:25\n",
            "2525Number of images found: \n",
            " 2525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2525  \n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:16<00:00, 16.42s/it]\n",
            "100%|██████████| 1/1 [00:24<00:00, 24.20s/it]\n",
            "100%|██████████| 1/1 [00:24<00:00, 24.64s/it]\n",
            "100%|██████████| 1/1 [00:24<00:00, 24.74s/it]\n",
            "100%|██████████| 1/1 [00:25<00:00, 25.14s/it]\n",
            "100%|██████████| 1/1 [00:25<00:00, 25.18s/it]\n",
            "100%|██████████| 1/1 [00:25<00:00, 25.49s/it]\n",
            "100%|██████████| 1/1 [00:25<00:00, 25.60s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Execution for Data processing time: 54.06022810935974\n",
            "Loading data generator...\n",
            "Number of images found: 53\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 1507.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data generator...\n",
            "Number of images found: 53\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 2038.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "Validation Loss: nan\n",
            "Model Execution time: 0.008009195327758789\n",
            "overall time of execution : 54.0682373046875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import time\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tqdm import tqdm\n",
        "from joblib import Parallel, delayed\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "IMAGE_SIZE = 256\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def load_data(image_path, image_size):\n",
        "    try:\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            return None\n",
        "        image = cv2.resize(image, (image_size, image_size))\n",
        "        image = image / 255.0\n",
        "        return image\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "def get_image_paths(folder_path):\n",
        "    image_paths = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(('.png', '.jpg')):\n",
        "            image_paths.append(os.path.join(folder_path, filename))\n",
        "    return image_paths\n",
        "\n",
        "def data_generator(image_paths, batch_size=32, image_size=128):\n",
        "    print('Loading data generator...')\n",
        "    print('Number of images found:', len(image_paths))\n",
        "    num_samples = len(image_paths)\n",
        "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
        "\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "    batch_list = []\n",
        "    for batch_idx in tqdm(range(num_batches)):\n",
        "        start_idx = batch_idx * batch_size\n",
        "        end_idx = min((batch_idx + 1) * batch_size, len(image_paths))\n",
        "        batch_paths = image_paths[start_idx:end_idx]\n",
        "        batch_images = []\n",
        "        for image_path in batch_paths:\n",
        "            image_data = load_data(image_path, image_size)\n",
        "            if image_data is not None:\n",
        "                # Apply data augmentation\n",
        "                image_data = np.expand_dims(image_data, axis=0)\n",
        "                augmented_image = next(datagen.flow(image_data, batch_size=1))[0]\n",
        "                batch_images.append(augmented_image)\n",
        "\n",
        "        if batch_images:\n",
        "            batch_list.append(np.array(batch_images))\n",
        "    return batch_list\n",
        "\n",
        "def process_data(image_folder, num_processes, num_threads):\n",
        "    image_paths = get_image_paths(image_folder)\n",
        "    chunk_size = len(image_paths) // num_processes\n",
        "    chunks = [image_paths[i:i + chunk_size] for i in range(0, len(image_paths), chunk_size)]\n",
        "\n",
        "    results = Parallel(n_jobs=num_processes, backend=\"multiprocessing\")(\n",
        "        delayed(data_generator)(chunk, BATCH_SIZE, IMAGE_SIZE) for chunk in chunks\n",
        "    )\n",
        "\n",
        "    for result in results:\n",
        "        for batch in result:\n",
        "            pass\n",
        "\n",
        "def build_dce_net():\n",
        "    input_img = layers.Input(shape=[None, None, 3])\n",
        "    conv1 = layers.Conv2D(\n",
        "        32, (3, 3), strides=(1, 1), activation='relu', padding='same'\n",
        "    )(input_img)\n",
        "    conv2 = layers.Conv2D(\n",
        "        32, (3, 3), strides=(1, 1), activation='relu', padding='same'\n",
        "    )(conv1)\n",
        "    conv3 = layers.Conv2D(\n",
        "        32, (3, 3), strides=(1, 1), activation='relu', padding='same'\n",
        "    )(conv2)\n",
        "    conv4 = layers.Conv2D(\n",
        "        32, (3, 3), strides=(1, 1), activation='relu', padding='same'\n",
        "    )(conv3)\n",
        "    int_con1 = layers.Concatenate(axis=-1)([conv4, conv3])\n",
        "    conv5 = layers.Conv2D(\n",
        "        32, (3, 3), strides=(1, 1), activation='relu', padding='same'\n",
        "    )(int_con1)\n",
        "    int_con2 = layers.Concatenate(axis=-1)([conv5, conv2])\n",
        "    conv6 = layers.Conv2D(\n",
        "        32, (3, 3), strides=(1, 1), activation='relu', padding='same'\n",
        "    )(int_con2)\n",
        "    int_con3 = layers.Concatenate(axis=-1)([conv6, conv1])\n",
        "    x_r = layers.Conv2D(24, (3, 3), strides=(1, 1), activation='tanh', padding='same')(\n",
        "        int_con3\n",
        "    )\n",
        "    return Model(inputs=input_img, outputs=x_r)\n",
        "\n",
        "# Define custom loss functions\n",
        "def color_constancy_loss(x):\n",
        "    mean_rgb = tf.reduce_mean(x,axis=(1,2),keepdims=True)\n",
        "    mr,mg,mb = mean_rgb[:,:,:,0],mean_rgb[:,:,:,1],mean_rgb[:,:,:,2]\n",
        "    d_rg = tf.square(mr - mg)\n",
        "    d_rb = tf.square(mr - mb)\n",
        "    d_gb = tf.square(mb - mg)\n",
        "    return tf.sqrt(tf.square(d_rg) + tf.square(d_rb) + tf.square(d_gb))\n",
        "\n",
        "def exposure_loss(x, mean_val=0.6):\n",
        "    x = tf.reduce_mean(x, axis=3, keepdims=True)\n",
        "    mean = tf.nn.avg_pool2d(x, ksize=16, strides=16, padding='VALID')\n",
        "    return tf.reduce_mean(tf.square(mean - mean_val))\n",
        "\n",
        "def illumination_smoothness_loss(x):\n",
        "    batch_size = tf.shape(x)[0]\n",
        "    h_x = tf.shape(x)[1]\n",
        "    w_x = tf.shape(x)[2]\n",
        "    count_h = (tf.shape(x)[2] - 1) * tf.shape(x)[3]\n",
        "    count_w = tf.shape(x)[2] * (tf.shape(x)[3] - 1)\n",
        "    h_tv = tf.reduce_sum(tf.square((x[:,1:,:,:] - x[:,:h_x - 1, :, :])))\n",
        "    w_tv = tf.reduce_sum(tf.square((x[:,:,1:,:] - x[:,:,:w_x - 1, :])))\n",
        "    batch_size = tf.cast(count_h,dtype=tf.float32)\n",
        "    count_h = tf.cast(count_h,dtype=tf.float32)\n",
        "    count_w = tf.cast(count_w,dtype=tf.float32)\n",
        "    return 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n",
        "\n",
        "class SpatialConsistencyLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(SpatialConsistencyLoss, self).__init__(**kwargs)\n",
        "        self.left_kernel = tf.constant([[[[0, 0, 0]], [[-1, 1, 0]], [[0, 0, 0]]]], dtype=tf.float32)\n",
        "        self.right_kernel = tf.constant([[[[0, 0, 0]], [[0, 1, -1]], [[0, 0, 0]]]], dtype=tf.float32)\n",
        "        self.up_kernel = tf.constant([[[[0, -1, 0]], [[0, 1, 0]], [[0, 0, 0]]]], dtype=tf.float32)\n",
        "        self.down_kernel = tf.constant([[[[0, 0, 0]], [[0, 1, 0]], [[0, -1, 0]]]], dtype=tf.float32)\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        original_mean = tf.reduce_mean(y_true, 3, keepdims=True)\n",
        "        enhanced_mean = tf.reduce_mean(y_pred, 3, keepdims=True)\n",
        "        original_pool = tf.nn.avg_pool2d(original_mean, ksize=4, strides=4, padding=\"VALID\")\n",
        "        enhanced_pool = tf.nn.avg_pool2d(enhanced_mean, ksize=4, strides=4, padding=\"VALID\")\n",
        "        d_original_left = tf.nn.conv2d(original_pool, self.left_kernel, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "        d_original_right = tf.nn.conv2d(original_pool, self.right_kernel, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "        d_original_up = tf.nn.conv2d(original_pool, self.up_kernel, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "        d_original_down = tf.nn.conv2d(original_pool, self.down_kernel, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "        d_enhanced_left = tf.nn.conv2d(enhanced_pool, self.left_kernel, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "        d_enhanced_right = tf.nn.conv2d(enhanced_pool, self.right_kernel, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "        d_enhanced_up = tf.nn.conv2d(enhanced_pool, self.up_kernel, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "        d_enhanced_down = tf.nn.conv2d(enhanced_pool, self.down_kernel, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "\n",
        "        d_left = tf.square(d_original_left - d_enhanced_left)\n",
        "        d_right = tf.square(d_original_right - d_enhanced_right)\n",
        "        d_up = tf.square(d_original_up - d_enhanced_up)\n",
        "        d_down = tf.square(d_original_down - d_enhanced_down)\n",
        "        return d_left + d_right + d_up + d_down\n",
        "\n",
        "class ZeroDCE(Model):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(ZeroDCE, self).__init__(**kwargs)\n",
        "        self.dce_model = build_dce_net()\n",
        "        self.spatial_constancy_loss = SpatialConsistencyLoss()\n",
        "\n",
        "    def call(self, data):\n",
        "        return self.dce_model(data)\n",
        "\n",
        "    def compute_losses(self, data, output):\n",
        "        loss_spatial_constancy = tf.reduce_mean(self.spatial_constancy_loss(data, output))\n",
        "        loss_color_constancy = 5 * tf.reduce_mean(color_constancy_loss(output))\n",
        "        loss_exposure = 10 * tf.reduce_mean(exposure_loss(output))\n",
        "        loss_illumination = 200 * illumination_smoothness_loss(output)\n",
        "        total_loss = loss_spatial_constancy + loss_color_constancy + loss_exposure + loss_illumination\n",
        "        return {\n",
        "            \"total_loss\": total_loss,\n",
        "            \"illumination_smoothness_loss\": loss_illumination,\n",
        "            \"spatial_constancy_loss\": loss_spatial_constancy,\n",
        "            \"color_constancy_loss\": loss_color_constancy,\n",
        "            \"exposure_loss\": loss_exposure,\n",
        "        }\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            output = self.dce_model(data)\n",
        "            losses = self.compute_losses(data, output)\n",
        "        gradients = tape.gradient(losses[\"total_loss\"], self.dce_model.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.dce_model.trainable_weights))\n",
        "        return losses\n",
        "\n",
        "    def test_step(self, data):\n",
        "        output = self.dce_model(data)\n",
        "        return self.compute_losses(data, output)\n",
        "\n",
        "def train_model(model, train_batches, val_batches, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        for batch in train_batches:\n",
        "            losses = model.train_step(batch)\n",
        "            print(\"Training Loss:\", losses[\"total_loss\"].numpy())\n",
        "        val_losses = []\n",
        "        for val_batch in val_batches:\n",
        "            val_loss = model.test_step(val_batch)\n",
        "            val_losses.append(val_loss[\"total_loss\"].numpy())\n",
        "        print(\"Validation Loss:\", np.mean(val_losses))\n",
        "\n",
        "\n",
        "# Main part of the script\n",
        "train_image_folder = 'first_zero_de_images'\n",
        "val_image_folder = 'first_zero_de_images'\n",
        "num_processes = int(input(\"Enter the number of processes: \"))\n",
        "num_threads = int(input(\"Enter the number of threads per process: \"))\n",
        "\n",
        "start_time = time.time()\n",
        "process_data(train_image_folder, num_processes, num_threads)\n",
        "process_data(val_image_folder, num_processes, num_threads)\n",
        "end_time = time.time()\n",
        "print(\"Execution for Data processing time:\", end_time - start_time)\n",
        "p1 = end_time - start_time\n",
        "\n",
        "train_data_generator = data_generator(train_image_folder)\n",
        "val_data_generator = data_generator(val_image_folder)\n",
        "\n",
        "zero_dce_model = ZeroDCE()\n",
        "zero_dce_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
        "\n",
        "start_time = time.time()\n",
        "train_model(zero_dce_model, train_data_generator, val_data_generator, epochs=1)\n",
        "end_time = time.time()\n",
        "m1 = end_time - start_time\n",
        "print(\"Model Execution time:\", end_time - start_time)\n",
        "\n",
        "print(\"overall time of execution :\",p1+m1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
